# Legal Q&A RAG System

A production-ready Retrieval-Augmented Generation (RAG) system that answers legal questions by combining semantic search with AI generation. Built as a technical demonstration of modern RAG architecture.

## ğŸŒŸ Features

### Core Functionality
- ğŸ” **Semantic Search**: Vector-based FAQ retrieval using embeddings
- ğŸ¤– **AI Generation**: Contextual answers powered by GPT-4
- ğŸ“Š **Interaction Logging**: Complete query history with analytics
- âš¡ **Fast Response**: 1-3 second average response time
- ğŸ¯ **Source Attribution**: Shows which FAQs informed each answer

### Technical Excellence
- ğŸ³ **Fully Containerized**: One-command Docker Compose setup
- ğŸ”„ **Async Operations**: Non-blocking I/O for better performance
- ğŸ›¡ï¸ **Error Handling**: Graceful degradation with fallback responses
- ğŸ“ **Auto Documentation**: Interactive API docs with Swagger
- ğŸ¨ **Modern UI**: Clean, responsive interface with Tailwind CSS

## ğŸ“‹ Quick Start

### Prerequisites
- Docker & Docker Compose
- OpenAI API Key ([Get one here](https://platform.openai.com/api-keys))

### Setup (2 minutes)

1. **Clone and configure**:
```bash
git clone <repository-url>
cd RAG-System
```

2. **Add your OpenAI API key**:
```bash
# Create backend/.env file
echo "OPENAI_API_KEY=your-key-here" > backend/.env
```

3. **Start the system**:
```bash
docker-compose up --build
```

4. **Access the application**:
- Frontend: http://localhost:3000
- API Docs: http://localhost:8000/docs

ğŸ“– **For detailed setup instructions, see [SETUP_GUIDE.md](SETUP_GUIDE.md)**

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Frontend (React)                    â”‚
â”‚  - Query Input Interface                            â”‚
â”‚  - Response Display                                 â”‚
â”‚  - Interaction History                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend (FastAPI)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  RAG Pipeline                                â”‚   â”‚
â”‚  â”‚  1. Query â†’ Embedding                        â”‚   â”‚
â”‚  â”‚  2. Vector Search â†’ Retrieve FAQs            â”‚   â”‚
â”‚  â”‚  3. Context + Prompt â†’ LLM                   â”‚   â”‚
â”‚  â”‚  4. Generate Answer                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                    â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Vector Store  â”‚    â”‚  OpenAI API        â”‚      â”‚
â”‚  â”‚ (Qdrant)      â”‚    â”‚  - Embeddings      â”‚      â”‚
â”‚  â”‚ - 10 FAQs     â”‚    â”‚  - GPT-4 Turbo     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ“– **For detailed architecture, see [ARCHITECTURE.md](ARCHITECTURE.md)**

## ğŸ¯ Tech Stack

| Component | Technology | Why This Choice |
|-----------|-----------|-----------------|
| **Backend** | FastAPI | Async support, auto API docs, Pydantic validation |
| **Frontend** | React 18 + Vite | Component reusability, fast HMR, industry standard |
| **Vector DB** | Qdrant | Production-ready, scales to millions of vectors |
| **Embeddings** | OpenAI text-embedding-3-small | High quality, 1536 dims, cost-effective |
| **LLM** | GPT-4 Turbo | Best-in-class answer quality |
| **Styling** | Tailwind CSS | Rapid development, consistent design |
| **Logging** | SQLite | Zero config, SQL queries, easy to inspect |
| **Deployment** | Docker Compose | Consistent environment, one-command startup |

## Quick Start

### Prerequisites

- Docker & Docker Compose
- OpenAI API Key

### Setup

1. Clone the repository
```bash
git clone <repository-url>
cd RAG-System
```

2. Configure environment variables
```bash
cp backend/.env.example backend/.env
# Edit backend/.env and add your OPENAI_API_KEY
```

3. Start all services
```bash
docker-compose up --build
```

4. Access the application
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Documentation: http://localhost:8000/docs

## Project Structure

```
RAG-System/
â”œâ”€â”€ backend/              # FastAPI application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py      # Application entry point
â”‚   â”‚   â”œâ”€â”€ config.py    # Configuration management
â”‚   â”‚   â”œâ”€â”€ models/      # Data models
â”‚   â”‚   â”œâ”€â”€ services/    # Business logic
â”‚   â”‚   â”œâ”€â”€ api/         # API routes
â”‚   â”‚   â””â”€â”€ data/        # FAQ dataset
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/            # React application
â”‚   â””â”€â”€ src/
â”œâ”€â”€ docker-compose.yml   # Service orchestration
â””â”€â”€ README.md
```

## Development

### Backend Development

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### Frontend Development

```bash
cd frontend
npm install
npm run dev
```

## ğŸ“Š Sample Queries

Try these to test the system:

1. **Personal Injury**: "What is the statute of limitations for personal injury claims?"
2. **Contract Law**: "Can I break a contract without penalty?"
3. **Employment**: "What constitutes wrongful termination from employment?"
4. **Property**: "What are my rights as a landlord to evict a tenant?"
5. **Criminal**: "What are my rights if I'm arrested?"

## ğŸ“š API Endpoints

### Main Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/ask` | Submit question, get AI answer with sources |
| GET | `/api/logs` | Retrieve interaction history |
| GET | `/api/stats` | Get system statistics |
| GET | `/api/health` | Health check (Qdrant, OpenAI status) |

### Example Request

```bash
curl -X POST "http://localhost:8000/api/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is the statute of limitations?",
    "include_sources": true
  }'
```

### Example Response

```json
{
  "answer": "The statute of limitations varies by state...",
  "sources": [
    {
      "faq_id": "faq_001",
      "question": "What is the statute of limitations...",
      "category": "Personal Injury",
      "similarity_score": 0.89
    }
  ],
  "response_time_ms": 1243,
  "timestamp": "2025-10-06T14:30:00Z"
}
```

## ğŸ§ª Testing & Evaluation

### Functional Criteria âœ…

- âœ… **10 Legal FAQs**: Covering 5 categories (Personal Injury, Contract, Employment, Property, Criminal)
- âœ… **Queryable Data**: Qdrant vector database with semantic search
- âœ… **Simple Interface**: Clean React UI with sample questions
- âœ… **Top 2 Retrieval**: Configurable top-k with similarity threshold
- âœ… **AI Generation**: GPT-4 with contextual prompting
- âœ… **Clear Display**: Formatted answers with source attribution
- âœ… **Interaction Logging**: SQLite database with full history
- âœ… **Demo Ready**: `docker-compose up` - runs in 2 minutes

### Technical Criteria âœ…

**Architecture & Design**:
- Modular layers (Frontend, API, Services, Data)
- Service-oriented architecture (Embeddings, Retrieval, Generation)
- Extensible to 10,000+ FAQs without code changes
- Production-ready patterns (async, dependency injection, error handling)

**Code Quality**:
- Type hints and Pydantic validation
- Comprehensive docstrings
- Clear variable naming
- Error handling with graceful fallbacks
- Configuration via environment variables

**Efficiency**:
- Async I/O for all API calls
- Batch embedding generation
- Cached configuration
- 1-3 second average response time

**Technical Choices**:
- FastAPI (async + auto docs) > Flask
- Qdrant (scalable) > in-memory search
- OpenAI (reliable + quality) > open-source models
- SQLite (sufficient for MVP) > PostgreSQL

## ğŸ“– Documentation

- **[SETUP_GUIDE.md](SETUP_GUIDE.md)**: Complete setup instructions, troubleshooting
- **[ARCHITECTURE.md](ARCHITECTURE.md)**: Technical architecture, design decisions, scaling strategies
- **API Docs**: http://localhost:8000/docs (interactive Swagger UI)

## ğŸ“ Learning Notes

### What is RAG?

**Retrieval-Augmented Generation** combines:
1. **Retrieval**: Find relevant documents from a knowledge base
2. **Augmentation**: Add retrieved context to LLM prompt
3. **Generation**: LLM generates answer grounded in real data

### Why RAG Matters

- **Prevents hallucination**: LLM answers based on actual data
- **Current information**: Update knowledge base without retraining
- **Source attribution**: Show which documents informed the answer
- **Cost-effective**: Cheaper than fine-tuning models

### Industry Usage

This exact pattern is used by:
- ChatGPT Enterprise (custom knowledge bases)
- GitHub Copilot (code context retrieval)
- Customer support AI (help article retrieval)
- Legal research tools (case law retrieval)

## ğŸš€ Extending the System

### Add More FAQs

1. Edit `backend/app/data/legal_faqs.json`
2. Add new FAQ entries with same schema
3. Restart backend: `docker-compose restart backend`
4. FAQs automatically indexed on startup

### Change LLM Model

In `backend/.env`:
```env
LLM_MODEL=gpt-3.5-turbo  # Cheaper, faster
# or
LLM_MODEL=gpt-4-turbo-preview  # Higher quality (current)
```

### Adjust Retrieval Settings

```env
TOP_K_RESULTS=3  # Return top 3 FAQs instead of 2
SIMILARITY_THRESHOLD=0.6  # Lower threshold = more results
```

## ğŸ› Troubleshooting

**OpenAI API Key Error**:
```bash
# Verify .env file exists and has correct key
cat backend/.env
# Restart backend
docker-compose restart backend
```

**Port Already in Use**:
```bash
# Change ports in docker-compose.yml
ports:
  - "3001:3000"  # Change 3000 to 3001
```

**FAQs Not Loading**:
```bash
# Reset Qdrant storage
docker-compose down -v
docker-compose up --build
```

See [SETUP_GUIDE.md](SETUP_GUIDE.md) for more troubleshooting.

## ğŸ“ˆ Performance Metrics

- **Query Response**: 1-3 seconds average
- **Embedding Generation**: ~200ms
- **Vector Search**: ~10-50ms  
- **LLM Generation**: ~1-2 seconds
- **Concurrent Users**: 10-20 (current setup)

## ğŸ”’ Security Notes

- API keys stored in `.env` (not committed to Git)
- CORS restricted to localhost (development)
- Input validation with Pydantic
- For production: Add authentication, rate limiting, HTTPS

## ğŸ“ License

MIT License - See LICENSE file for details

---

## ğŸ™ Acknowledgments

Built with:
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [React](https://react.dev/) - UI component library
- [Qdrant](https://qdrant.tech/) - Vector similarity search engine
- [OpenAI](https://openai.com/) - Embeddings and language models
- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework

---

**Questions?** Check the documentation:
- ğŸ“– [SETUP_GUIDE.md](SETUP_GUIDE.md) - Setup and troubleshooting
- ğŸ—ï¸ [ARCHITECTURE.md](ARCHITECTURE.md) - Technical deep dive
- ğŸ“š API Docs - http://localhost:8000/docs
